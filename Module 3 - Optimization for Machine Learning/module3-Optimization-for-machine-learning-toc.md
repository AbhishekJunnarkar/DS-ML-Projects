# Table of contents

----
----

## 1. Optimization Formulations

### 1.1.What is Optimization

#### 1.1.1 Single variable objective function 
  - Finding the lowest point on a curve
    
#### 1.1.2 Multi variable objective function
  - Finding the lowest point on a surface (not just a curve)

#### 1.1.3 Tayler Series Expansion
- The Taylor series expansion is used to approximate complex functions using simpler polynomial expressions.

----

### 1.2 Concept of Optimization

#### 1.2.1 Key Terminology
- Maxima
- Minima
- Saddle point
#### 1.2.2 Generalized optimality conditions
- Necessary conditions
- Sufficient conditions
- Illustrative Example: Optimizing Cone Volume with a Fixed Dimension Sum

----

### 1.3 Generalized Optimization formulation
- How to find the optimum value?
- Double Derivative or slope of the curve
- Minimization Problem Example(34)
- Why derivative should be Zero for optimization?
- Objective Functions
- Equality constraints
- Inequity constraints
- Bounds
- Single Objective Optimization
- Multi Objective Optimization
 
 ----
 
### 1.4 Use of Optimization in machine learning
- Curve fitting optimization(Regression)
- Illustrative Example
- Python Problem 1: Find the minimum or maximum of a equation I(x1) or I(x2)
- Python Problem 2: Curve fitting problem

----
----

## 2. Gradient and Search-Based Optimisation for Machine Learning

### 2.1 Multi-variable Gradient Based Optimimzation Techniques

#### 2.1.1 Gradient descent
- Example 1: Minimize a function I using gradient descent
#### 2.1.2 Newton's method
- Example 2: Minimize a function I using Newton's method
#### 2.1.3 Comparison of Gradient descent vs. Newton's method
    
----

### 2.2 Constrained Optimization Techniques

#### 2.2.1 Variable Elimination
- Example 3: Minimize a function I using variable elimination method

#### 2.2.2 Lagrange Multipliers
- Example 4: Minimize a function I using variable elimination method
#### 2.2.3 Kuhn Tucker Conditions
- The Kuhn-Tucker conditions, more formally known as the Karush-Kuhn-Tucker (KKT) conditions,
are a set of mathematical rules used to find the optimal solution for certain constrained optimization problems
#### 2.2.4 Penalty functions
- Penalty functions are used in constrained optimization to transform a constrained problem into an 
unconstrained one â€” by adding a "penalty" to the objective function when the constraints are violated.

----
----

## 3. Linear, Quadratic, and Nonlinear Programming
----
### 3.1 Linear Programming
#### 3.1.1 Standard form of Linear Programming
#### 3.1.2 Canonical form of Linear Equations
----
### 3.2 Methods used for Solving Linear Programming
#### 3.2.1 Simplex Algorithm
#### 3.2.2 Two-phase Simplex Algorithm
#### 3.2.3 Specialized Quadratic Algorithm
#### 3.2.4 Duality
#### 3.2.5 Quadratic Programming
----
### 3.2 Integer Programming
----
### 3.3 Non-Linear Programming

## 4. Multi-objective and Multi-Criteria Decision-Making - Evolutionary Tools

### 4.1 Multi-objective Optimization

## Self-learning Project: Multi Objective Optimisation in Stock investments